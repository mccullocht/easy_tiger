use std::{io, num::NonZero, ops::RangeInclusive, sync::Arc};

use clap::Args;
use easy_tiger::{
    input::VecVectorStore,
    kmeans,
    spann::{centroid_stats::CentroidStats, PostingKey, TableIndex},
    vamana::{
        mutate::{delete_vector, upsert_vector},
        search::GraphSearcher,
        wt::SessionGraphVectorIndex,
        GraphVectorIndex, GraphVectorStore,
    },
};
use tracing::warn;
use wt_mdb::{session::TransactionGuard, Connection, Error, Result, Session, TypedCursor};

use crate::ui::progress_spinner;

// TODO: almost all of these arguments belong in the index config.
#[derive(Args)]
pub struct RebalanceArgs {
    /// Number of rebalancing iterations to perform.
    #[arg(long, default_value_t = NonZero::new(1).unwrap())]
    iterations: NonZero<usize>,

    /// If true, commit the transaction generated by rebalancing operations.
    #[arg(long, default_value_t = false)]
    commit: bool,

    /// Random seed used for clustering computations.
    /// Use a fixed value for repeatability.
    #[arg(long, default_value_t = 0x7774_7370414E4E)]
    seed: u64,
}

#[derive(Debug, Default, Copy, Clone)]
struct BalanceSummary {
    in_bounds: usize,

    below_bounds: usize,
    below_exemplar: Option<(usize, usize)>,

    above_bounds: usize,
    above_exemplar: Option<(usize, usize)>,
}

impl BalanceSummary {
    fn new(stats: &CentroidStats, bounds: RangeInclusive<usize>) -> Self {
        let mut summary = Self::default();
        for (i, c) in stats.assignment_counts_iter().map(|(i, c)| (i, c as usize)) {
            if bounds.contains(&c) {
                summary.in_bounds += 1;
            } else if c < *bounds.start() {
                summary.below_bounds += 1;
                summary.below_exemplar = summary
                    .below_exemplar
                    .map(|(j, d)| if c < d { (i, c) } else { (j, d) })
                    .or(Some((i, c)));
            } else {
                summary.above_bounds += 1;
                summary.above_exemplar = summary
                    .above_exemplar
                    .map(|(j, d)| if c > d { (i, c) } else { (j, d) })
                    .or(Some((i, c)));
            }
        }
        summary
    }

    fn total_clusters(&self) -> usize {
        self.in_bounds + self.below_bounds + self.above_bounds
    }

    fn in_policy_fraction(&self) -> f64 {
        self.in_bounds as f64 / self.total_clusters() as f64
    }
}

pub struct Rebalancer {
    index: Arc<TableIndex>,
    head_index: SessionGraphVectorIndex,
}

impl Rebalancer {
    fn new(index: Arc<TableIndex>, session: Session) -> Self {
        assert_eq!(
            index.config().replica_count,
            1,
            "rebalance only implemented for replica count 1"
        );
        let head_index = SessionGraphVectorIndex::new(Arc::clone(index.head_config()), session);
        Self { index, head_index }
    }

    fn session(&self) -> &Session {
        self.head_index.session()
    }

    fn centroid_stats(&self) -> Result<CentroidStats> {
        CentroidStats::from_index_stats(&self.head_index.session(), &self.index)
    }

    fn summary(&self, stats: &CentroidStats) -> BalanceSummary {
        BalanceSummary::new(stats, self.centroid_len_range())
    }

    fn centroid_len_range(&self) -> RangeInclusive<usize> {
        self.index.config().min_centroid_len..=self.index.config().max_centroid_len
    }

    // Remove `centroid_id` and merge each of its vectors into the next closest centroid.
    fn merge_centroid(&self, centroid_id: usize) -> Result<()> {
        // Collect all of the vectors for the centroid to merge.
        let mut posting_cursor = self
            .head_index
            .session()
            .get_or_create_typed_cursor::<PostingKey, Vec<u8>>(self.index.postings_table_name())?;
        let vectors = self.drain_centroid(centroid_id, &mut posting_cursor)?;

        // Remove the centroid from the graph.
        delete_vector(centroid_id as i64, &self.head_index)?;

        // If the centroid is already empty then there is nothing to do.
        if vectors.is_empty() {
            return Ok(());
        }

        // XXX logic below needs to be shared with the index writer.
        // Query the head index for each vector and assign a new centroid.
        let coder = self
            .index
            .config()
            .posting_coder
            .new_coder(self.index.head_config().config().similarity);
        let mut float_vector =
            vec![0.0f32; coder.dimensions(self.index.head_config().config().dimensions.get())];
        let mut searcher = GraphSearcher::new(self.index.config().head_search_params);
        posting_cursor.reset()?;
        let mut centroid_cursor = self
            .head_index
            .session()
            .get_record_cursor(&self.index.centroids_table_name())?;
        for (record_id, vector) in vectors {
            coder.decode_to(&vector, &mut float_vector);
            let candidates = searcher.search(&float_vector, &self.head_index)?;
            assert!(!candidates.is_empty());
            let centroid_id = candidates[0].vertex() as u32;
            let key = PostingKey::new(centroid_id, record_id);
            posting_cursor.set(key, &vector)?;
            centroid_cursor.set(record_id, &centroid_id.to_le_bytes())?;
        }

        Ok(())
    }

    fn split_centroid(&self, centroid_id: usize, next_centroid_id: usize) -> Result<()> {
        let mut posting_cursor = self
            .head_index
            .session()
            .get_or_create_typed_cursor::<PostingKey, Vec<u8>>(self.index.postings_table_name())?;
        let vectors = self.drain_centroid(centroid_id, &mut posting_cursor)?;
        assert!(!vectors.is_empty());

        // Unpack all of the vectors as floats and split into two clusters.
        let posting_format = self.index.config().posting_coder;
        let similarity = self.index.head_config().config().similarity;
        let posting_coder = posting_format.new_coder(similarity);
        let mut scratch_vector = vec![0.0f32; self.index.head_config().config().dimensions.get()];
        let mut clustering_vectors =
            VecVectorStore::with_capacity(scratch_vector.len(), vectors.len());
        for (_, vector) in vectors.iter() {
            posting_coder.decode_to(&vector, &mut scratch_vector);
            clustering_vectors.push(&scratch_vector);
        }
        posting_cursor.reset()?;

        let centroids = match kmeans::binary_partition(
            &clustering_vectors,
            100,
            self.index.config().min_centroid_len,
        ) {
            Ok(r) => r,
            Err(r) => {
                warn!("split_centroid: binary partition of {centroid_id} failed to converge!");
                r
            }
        };

        // Extract the original centroid vector from the head index and delete original centroid.
        let mut head_vectors = self.head_index.high_fidelity_vectors()?;
        let head_coder = head_vectors.new_coder();
        let original_centroid = head_coder.decode(
            head_vectors
                .get(centroid_id as i64)
                .unwrap_or(Err(Error::not_found_error()))?,
        );
        delete_vector(centroid_id as i64, &self.head_index)?;

        // For each vector if it is closer to the original centroid than either of the new centroids
        // then query the whole index to select a new assignment. Otherwise assign it to the closest
        // of the two new centroids.
        let mut params = self.index.config().head_search_params;
        // TODO: figure out if nearby update beam width needs to be configurable.
        // TODO: write a tool that figures out how many vectors are not assigned to the nearest
        // centroid.
        params.beam_width = NonZero::new(64).unwrap();
        let mut searcher = GraphSearcher::new(params);
        let nearby_clusters = searcher.search(&original_centroid, &self.head_index)?;

        searcher = GraphSearcher::new(self.index.config().head_search_params);
        let c0_dist_fn = posting_format.query_vector_distance_f32(original_centroid, similarity);
        let c1_dist_fn = posting_format.query_vector_distance_f32(&centroids[0], similarity);
        let c2_dist_fn = posting_format.query_vector_distance_f32(&centroids[1], similarity);
        let mut centroid_cursor = self
            .head_index
            .session()
            .get_record_cursor(&self.index.centroids_table_name())?;
        for (record_id, vector) in vectors {
            let c0_dist = c0_dist_fn.distance(&vector);
            let c1_dist = c1_dist_fn.distance(&vector);
            let c2_dist = c2_dist_fn.distance(&vector);
            let new_centroid_id = if c0_dist <= c1_dist && c0_dist <= c2_dist {
                posting_coder.decode_to(&vector, &mut scratch_vector);
                searcher.search(&scratch_vector, &self.head_index)?[0].vertex() as u32
            } else if c1_dist < c2_dist {
                centroid_id as u32
            } else {
                next_centroid_id as u32
            };

            let key = PostingKey::new(new_centroid_id as u32, record_id);
            posting_cursor.set(key, &vector)?;
            centroid_cursor.set(record_id, &new_centroid_id.to_le_bytes())?;
        }

        // For a list of nearby centroids, examine all vectors and reassign them if they are closer
        // to one of the new centroids than they are to the current centroid.
        let mut update_posting_cursor = self
            .head_index
            .session()
            .get_or_create_typed_cursor::<PostingKey, Vec<u8>>(self.index.postings_table_name())?;
        for nearby_centroid_id in nearby_clusters.into_iter().map(|n| n.vertex() as u32) {
            let nearby_centroid = head_coder.decode(
                head_vectors
                    .get(nearby_centroid_id as i64)
                    .unwrap_or(Err(Error::not_found_error()))?,
            );
            let c0_dist_fn = posting_format.query_vector_distance_f32(nearby_centroid, similarity);

            posting_cursor.set_bounds(PostingKey::centroid_range(nearby_centroid_id))?;
            // SAFETY: memory remains valid because this path does not commit or rollback txns.
            while let Some(r) = unsafe { posting_cursor.next_unsafe() } {
                let (key, vector) = r?;
                let c0_dist = c0_dist_fn.distance(&vector);
                let c1_dist = c1_dist_fn.distance(&vector);
                let c2_dist = c2_dist_fn.distance(&vector);

                let assigned_centroid_id = if c1_dist < c0_dist {
                    centroid_id as u32
                } else if c2_dist < c0_dist {
                    next_centroid_id as u32
                } else {
                    continue;
                };

                let new_key = PostingKey::new(assigned_centroid_id, key.record_id);
                update_posting_cursor.remove(key)?;
                update_posting_cursor.set(new_key, &vector)?;
                centroid_cursor.set(key.record_id, &assigned_centroid_id.to_le_bytes())?;
            }
        }

        // Write the new centroids back into the index.
        upsert_vector(centroid_id as i64, &centroids[0], &self.head_index)?;
        upsert_vector(next_centroid_id as i64, &centroids[1], &self.head_index)?;

        Ok(())
    }

    /// Remove all the vectors from `centroid_id` using `cursor` and return them.
    fn drain_centroid(
        &self,
        centroid_id: usize,
        cursor: &mut TypedCursor<'_, PostingKey, Vec<u8>>,
    ) -> Result<Vec<(i64, Vec<u8>)>> {
        let mut vectors = vec![];
        cursor.set_bounds(PostingKey::centroid_range(centroid_id as u32))?;
        while let Some(r) = cursor.next() {
            let (key, vector) = r?;
            vectors.push((key.record_id, vector));
            cursor.remove(key)?;
        }
        Ok(vectors)
    }
}

fn print_balance_summary(summary: &BalanceSummary) {
    println!("SUMMARY");
    println!("  total:        {:6}", summary.total_clusters());
    println!(
        "  in bounds:    {:6} {:5.2}%",
        summary.in_bounds,
        summary.in_policy_fraction() * 100.0
    );
    println!(
        "  below bounds: {:6} examplar {:?}",
        summary.below_bounds, summary.below_exemplar
    );
    println!(
        "  above bounds: {:6} exemplar {:?}",
        summary.above_bounds, summary.above_exemplar
    );
}

pub fn rebalance(
    connection: Arc<Connection>,
    index_name: &str,
    args: RebalanceArgs,
) -> io::Result<()> {
    let index = Arc::new(TableIndex::from_db(&connection, index_name)?);
    let session = connection.open_session()?;

    let rebalancer = Rebalancer::new(index, session);
    let progress = if args.commit {
        Some(progress_spinner("rebalancing"))
    } else {
        None
    };
    for _ in 0..args.iterations.get() {
        let txn_guard = TransactionGuard::new(rebalancer.session(), None)?;
        let stats = rebalancer.centroid_stats()?;
        let summary = rebalancer.summary(&stats);

        if let Some(ref progress) = progress {
            progress.set_message(format!(
                "rebalancing {}/{} {:.2}% clusters in policy",
                summary.in_bounds,
                summary.total_clusters(),
                summary.in_policy_fraction() * 100.0
            ));
        }

        match (summary.below_exemplar, summary.above_exemplar) {
            (None, None) => {
                break;
            }
            (Some((to_merge, _)), _) => {
                rebalancer.merge_centroid(to_merge)?;
            }
            (_, Some((to_split, _))) => {
                rebalancer
                    .split_centroid(to_split, stats.available_centroid_ids().next().unwrap())?;
            }
        }

        if let Some(ref progress) = progress {
            txn_guard.commit(None)?;
            progress.inc(1);
        } else {
            break; // only ever one iteration if not committing.
        }
    }

    if let Some(progress) = progress {
        let stats = rebalancer.centroid_stats()?;
        let summary = rebalancer.summary(&stats);
        progress.set_message(format!(
            "rebalancing {}/{} {:.2}% clusters in policy",
            summary.in_bounds,
            summary.total_clusters(),
            summary.in_policy_fraction() * 100.0
        ));
        progress.finish_using_style();
    }
    let stats = rebalancer.centroid_stats()?;
    let summary = rebalancer.summary(&stats);
    if summary.in_policy_fraction() < 1.0 {
        print_balance_summary(&summary);
    }

    Ok(())
}
